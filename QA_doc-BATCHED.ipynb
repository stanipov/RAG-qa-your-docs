{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202352f-d578-4c6a-9dbc-ae86b59ee9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_docs_from_jsonl, uniquify, gen_report\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.hf_models import Engine\n",
    "from src.embedders import Embedders\n",
    "from src.faiss_store import VectorDB\n",
    "from src.retrievers import ComposedRetriever\n",
    "from src.prompts import RAGPromptTemplates\n",
    "from src.chains import WrapperChains\n",
    "\n",
    "from torch import bfloat16\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fedf0-5d54-4e63-bf6b-ca519101d536",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a98597-2785-405e-8597-b708655e8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "embed_cache = \"./cache/\"\n",
    "model_cache =  '/models/model_cache' \n",
    "\n",
    "# Embedding model\n",
    "embed_model_id = 'BAAI/bge-large-en-v1.5' \n",
    "embed_model_kwargs = {'device': 'cuda'}\n",
    "embed_show_prog = True\n",
    "\n",
    "# LLM\n",
    "model_id = \"cognitivecomputations/dolphin-2.6-mistral-7b-dpo-laser\"\n",
    "#model_id = \"cognitivecomputations/WestLake-7B-v2-laser\"  # - not bad\n",
    "#model_id = \"meta-llama/Llama-2-13b-chat-hf\" # a bit better than dolphin-2.6-mistral-7b-dpo-laser\n",
    "#model_id = \"google/gemma-7b\"\n",
    "#model_id = \"Deci/DeciLM-7B-instruct\" # bad, repetitions\n",
    "#model_id = \"Deci/DeciLM-7B\"  # bad\n",
    "\n",
    "\n",
    "load_4bit = True\n",
    "quant_type = \"nf4\"\n",
    "double_quant = True\n",
    "bnb_compute_type = bfloat16\n",
    "max_new_tokens = 2048\n",
    "# contrastive search\n",
    "# https://huggingface.co/blog/introducing-csearch\n",
    "penalty_alpha = 0.25\n",
    "top_k = 4\n",
    "\n",
    "# Vector store location\n",
    "vect_db_name = 'break_reg_qa'\n",
    "_dst = os.path.join(cwd, *(\"vector_db\", vect_db_name))\n",
    "os.makedirs(_dst, exist_ok=True)\n",
    "vector_store_location = _dst\n",
    "\n",
    "# Retriever\n",
    "# Will use MMR method\n",
    "# Modify search kwards accordingly\n",
    "search_type = 'mmr'\n",
    "search_kwargs = {\n",
    "    # Amount of documents to return (Default: 4)\n",
    "    \"k\": 20,\n",
    "    # Amount of documents to pass to MMR algorithm (Default: 20)\n",
    "    \"fetch_k\": 20,\n",
    "    # 1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
    "    \"lambda_mult\": 0.85\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59616597-4e25-427a-8a67-94524e24420c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cce5e-fd85-424a-89b5-4f87f01ecdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparsed_loc = \"/home/sf/data/py_proj/2024/RAG-qa-your-docs/preparsed_datadata/regulations.jsonl\"\n",
    "req_loc = \"/home/sf/data/py_proj/2024/RAG-qa-your-docs/preparsed_datadata/requirements.txt\"\n",
    "docs = load_docs_from_jsonl(preparsed_loc) \n",
    "requirements = []\n",
    "with open(req_loc, 'r') as f:\n",
    "    for line in f:\n",
    "        requirements.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7d3c1-0491-4cf5-8adf-f7c957478912",
   "metadata": {},
   "source": [
    "# Set up LLM and the embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682ff93-bcd3-41dc-8513-c724f89ab199",
   "metadata": {},
   "source": [
    "## Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffea51-b791-4552-9456-d669cdb750f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbedCLS = Embedders(model_id=embed_model_id,\n",
    "                     model_cache_dir=model_cache, \n",
    "                     model_kwargs=embed_model_kwargs, \n",
    "                     show_progress=embed_show_prog, \n",
    "                     embed_cache=embed_cache)\n",
    "EmbedCLS.load()\n",
    "embedder = EmbedCLS.get_embedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed23a9a-9f7c-4e6d-9813-633e6188aa69",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea11c10-ecba-4cf3-94b0-7b8f76dc16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=load_4bit,\n",
    "    bnb_4bit_quant_type=quant_type,\n",
    "    bnb_4bit_use_double_quant=double_quant,\n",
    "    bnb_4bit_compute_dtype=bnb_compute_type\n",
    ")\n",
    "\n",
    "LMEngine = Engine(model_id=model_id,\n",
    "                  cache_fld=model_cache,\n",
    "                  quant_config=bnb_config,\n",
    "                  device_map='auto',\n",
    "                  max_new_tokens=max_new_tokens,\n",
    "                  top_k=top_k, \n",
    "                  penalty_alpha=penalty_alpha)\n",
    "LMEngine.load()\n",
    "LMEngine.set_pipeline(batch_size=4)\n",
    "\n",
    "llm = LMEngine.get_llm()\n",
    "tokenizer = LMEngine.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bee37-0c38-47e9-9260-5d5e9bcff173",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LMEngine.penalty_alpha=penalty_alpha\n",
    "LMEngine.top_k=top_k\n",
    "LMEngine.set_pipeline(batch_size=4)\n",
    "llm = LMEngine.get_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90136469-2176-47ce-84ff-74325a70cd92",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f602ff-9107-4f0f-9ccb-b6f21a0cdcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VectorStore = VectorDB(embedder=embedder, vector_store_location=vector_store_location)\n",
    "VectorStore.create(docs)\n",
    "\n",
    "db = VectorStore.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc229b0-d00d-445f-8b06-fd6b0784f8bf",
   "metadata": {},
   "source": [
    "# Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d8167-0711-454b-ad31-87d9cd738b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ComplexRetriever = ComposedRetriever(db, search_type, **search_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9012e-ab13-48a5-8076-a0e06f74c418",
   "metadata": {},
   "source": [
    "# Chain & prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0e294-935f-4165-851b-44fbff14eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct1 = \"Given these documents:\"\n",
    "instruct2 = \"List ID and a brief explanation. \\\n",
    "Each explanation shall be no longer than three sentences. \\\n",
    "Keep the answer concise.\"\n",
    "# If you don't know the answer, just say that you don't know. \\\n",
    "query = \"Which of these regulations are relevant for the following query:\"\n",
    "\n",
    "prompt_template = RAGPromptTemplates.long_context(instruct1, instruct2, query)\n",
    "\n",
    "ChainsWrappers = WrapperChains(llm)\n",
    "chain = ChainsWrappers.make_long_context_chain(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f63bd-a5a6-439b-8154-4f0a92352375",
   "metadata": {},
   "source": [
    "# Single query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f35456-c029-42a6-bfff-fee7d9470def",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_loc = os.path.join(cwd, *(\"reports\", \"run1_02-23-2024\"))\n",
    "os.makedirs(report_loc, exist_ok=True)\n",
    "idx = 10 # normally start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91fea4-e15d-4d67-8b32-b0873f1d6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#idx -= 1 # in case of multiple questions on the same topic\n",
    "question = \"Manual shut off valve for the fuel piping shall be installed.\" #+ \\\n",
    "#\" We are looking for regulations that require a manual .\"\n",
    "\n",
    "fid = f\"{idx:04d}.txt\"\n",
    "\n",
    "extracted_docs = ComplexRetriever.get_docs(question)\n",
    "ans = chain.run(input_documents=extracted_docs, query=query)\n",
    "t = gen_report(question, ans, extracted_docs)\n",
    "print(t)\n",
    "\n",
    "fname = uniquify(os.path.join(report_loc, fid))\n",
    "\n",
    "with open(fname, 'w') as f:\n",
    "    f.writelines(t)\n",
    "\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b39265-41e5-460b-a169-16581467565b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Batched processing of the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b6f90-cdb5-47ae-8b2b-e2a88bd64edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_loc = os.path.join(cwd, *(\"reports\", \"run1_02-22-2024\"))\n",
    "os.makedirs(report_loc, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e14103-7470-498b-99a6-1bc3eb9f76ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, question in tqdm(enumerate(requirements)):\n",
    "    try:\n",
    "        report = []\n",
    "        extracted_docs = ComplexRetriever.get_docs(question)\n",
    "        ans = chain.run(input_documents=extracted_docs, query=query)\n",
    "    \n",
    "        # merge the docs into a string\n",
    "        extracted_docs_s = \"\"\n",
    "        _t = []\n",
    "        for doc in extracted_docs:\n",
    "            _t.append(doc.page_content)\n",
    "        extracted_docs_s = (\"\\n\\n\"+40*\"*\"+\"\\n\").join(_t)\n",
    "        \n",
    "        report = f\"\"\"QUESTION:\n",
    "{question}\n",
    "================================================================\n",
    "\n",
    "Generated response:\n",
    "{ans}\n",
    "================================================================\n",
    "\n",
    "Extracted documents {len(extracted_docs)}. \n",
    "These are the contens:\n",
    "\n",
    "{extracted_docs_s}\n",
    "        \"\"\"\n",
    "        fname = os.path.join(report_loc, f\"{idx:04d}.txt\")\n",
    "        with open(fname, 'w') as f:\n",
    "            f.writelines(report)\n",
    "    except Exception as e:\n",
    "        print(f\"{idx}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b25d95-33a2-481c-a015-e3103aa7e0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python-rag]",
   "language": "python",
   "name": "conda-env-python-rag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
